from subway_demo_env import SubwayCoolingEnv
from stable_baselines3 import PPO
from collections import Counter
import numpy as np

# íˆ¬í‘œ ê°’ â†’ ë ˆì´ë¸” ë§¤í•‘
VOTE_LABELS = {
    -2: "ë§¤ìš°ì¶¥ë‹¤",
    -1: "ì•½ê°„ì¶¥ë‹¤",
     0: "ë³´í†µì´ë‹¤",
     1: "ì•½ê°„ë¥ë‹¤",
     2: "ë§¤ìš°ë¥ë‹¤"
}

# ì˜¨ë„/í’ëŸ‰ ê°’ ë¦¬ìŠ¤íŠ¸ (envì™€ ë™ì¼í•˜ê²Œ ì •ì˜)
TEMP_VALUES = list(np.arange(18.0, 31.0, 1.0))  # 13ê°œ: 18.0 ~ 30.0
FAN_VALUES = [0.5, 1.0, 1.5]                    # 3ê°œ

def format_action(action):
    temp_idx, fan_idx = action
    temp_value = TEMP_VALUES[temp_idx]
    fan_value = FAN_VALUES[fan_idx]
    return f"(ì˜¨ë„: {temp_value:.1f}Â°C, í’ëŸ‰: {fan_value:.1f}ë‹¨ê³„)"

# í™˜ê²½ ë° í•™ìŠµëœ PPO ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
env = SubwayCoolingEnv()
model = PPO.load("ppo_subway_v2", env=env)

n_eval_episodes = 1  # ì›í•˜ëŠ” ì—í”¼ì†Œë“œ ìˆ˜ë§Œí¼ í‰ê°€

for episode in range(n_eval_episodes):
    obs, _ = env.reset()
    done = False
    total_reward = 0

    print(f"\nğŸ” [Episode {episode + 1} ì‹œì‘]")

    while not done:
        action, _ = model.predict(obs, deterministic=True)
        obs, reward, done, _, info = env.step(action)
        total_reward += reward

        # íˆ¬í‘œ ì²˜ë¦¬
        votes = info.get("votes", [])
        mean_vote = info.get("mean_vote", 0.0)
        vote_counter = Counter(votes)
        vote_summary = " | ".join(
            f"{VOTE_LABELS[v]}: {vote_counter.get(v, 0)}"
            for v in range(-2, 3)
        )

        # ì¶œë ¥ ì •ë¦¬
        action_str = format_action(action)
        print(f"Step {env.current_step:2d} | {vote_summary} | "
              f"Mean Vote: {mean_vote:+.2f} | Action: {action_str} | "
              f"AC ì„¤ì •: {env.ac_temp:.1f}Â°C / {env.ac_fan:.1f}ë‹¨ê³„ | Reward: {reward:.3f}")

    print(f"\nâœ… [Episode {episode + 1} ì¢…ë£Œ] Total Reward: {total_reward:.3f}")
